# # --PROJECT-COMMENT-BLOCK--
# File Path: repo_analyzer.py
# Author:
# Create Date:
# Description: A tool to analyze a software repository using a local Ollama model,
#              featuring streaming output, incremental reporting, and analysis history.
# # --PROJECT-COMMENT-BLOCK--

import os
import re
import sys
import json
from pathlib import Path
import requests
from typing import List, Set, Dict

# --- é…ç½® ---

PROJECT_TO_ANALYZE_PATH = r"D:\a666\open-lovable\docs"

# OLLAMA API çš„ç«¯ç‚¹
OLLAMA_API_URL = "http://localhost:11964/api/generate"
# ä½¿ç”¨çš„ Ollama æ¨¡å‹åç§°
OLLAMA_MODEL = "qwen3:latest"
# è¾“å‡ºæŠ¥å‘Šçš„æ–‡ä»¶å
OUTPUT_FILENAME = "repo_analysis_report.md"
#
HISTORY_FILENAME = ".repo_analysis_history.json"

# ç›®å½•å’Œæ–‡ä»¶æ’é™¤è§„åˆ™
EXCLUDE_DIRS: Set[str] = {
    ".git", ".venv", "venv", ".idea", ".vscode", "__pycache__",
    "node_modules", "build", "dist", "target", ".DS_Store", "logs", "node_modules",
}
EXCLUDE_EXTENSIONS: Set[str] = {
    ".pyc", ".log", ".tmp", ".swp", ".bak", ".zip", ".tar.gz", ".rar",
    ".png", ".jpg", ".jpeg", ".gif", ".svg", ".ico", ".mp4", ".mp3", ".wav",
}


# --- â­ æ–°å¢ï¼šå†å²è®°å½•ç®¡ç†åŠŸèƒ½ ---

def load_history(history_path: Path) -> Dict:
    """ä»JSONæ–‡ä»¶åŠ è½½åˆ†æå†å²ã€‚"""
    if not history_path.exists():
        return {}
    try:
        with open(history_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        print(f"âš ï¸  Warning: Could not load or parse history file '{history_path}'. Starting fresh. Error: {e}")
        return {}


def save_history(history_path: Path, history_data: Dict):
    """å°†åˆ†æå†å²ä¿å­˜åˆ°JSONæ–‡ä»¶ã€‚"""
    try:
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(history_data, f, indent=4)
    except IOError as e:
        print(f"âŒ  Error saving history file '{history_path}': {e}")


# --- â­ ä¼˜åŒ–ï¼šAIåˆ†æåŠŸèƒ½æ”¯æŒæµå¼è¾“å‡º ---

def analyze_file_with_ollama(file_path: str, file_content: str) -> str:
    """
    ä½¿ç”¨ Ollama API åˆ†æå•ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œå¹¶æµå¼è¾“å‡ºåˆ°æ§åˆ¶å°ã€‚
    """

    prompt = f"""
    ä½œä¸ºè½¯ä»¶æ¶æ„å¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹ä»£ç æ–‡ä»¶ã€‚

    æ–‡ä»¶è·¯å¾„ï¼š`{file_path}`

    æ–‡ä»¶å†…å®¹ï¼š
    {file_content}


    æ‚¨çš„åˆ†æåº”ç®€æ´æ˜äº†ï¼Œå¹¶é‡‡ç”¨Markdownæ ¼å¼ã€‚è¯·è¯†åˆ«ä»¥ä¸‹å†…å®¹ï¼š
    1. **ä¸»è¦ç›®çš„**ï¼šè¯¥æ–‡ä»¶çš„ä¸»è¦èŒè´£æ˜¯ä»€ä¹ˆï¼Ÿ
    2. **å…³é”®ç»„ä»¶**ï¼šç®€è¦æè¿°ä¸»è¦åŠŸèƒ½ã€ç±»æˆ–ç»„ä»¶åŠå…¶ä½œç”¨ã€‚
    3. **ä¾èµ–é¡¹**ï¼šè¯¥æ–‡ä»¶å¯èƒ½ä¸å…¶ä»–å“ªäº›é¡¹ç›®éƒ¨åˆ†äº§ç”Ÿäº¤äº’ï¼Ÿ
    4. **æ”¹è¿›å»ºè®®**ï¼šæä¾›ä¸€ä¸ªå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ˆä¾‹å¦‚ï¼šé‡æ„ã€å‘½åä¼˜åŒ–ã€æ·»åŠ æµ‹è¯•ç­‰ï¼‰ã€‚
    """

    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": True
    }

    raw_full_response = []
    print(f"\nğŸ§   Analyzing: {file_path}...")

    try:
        with requests.post(OLLAMA_API_URL, json=payload, stream=True, timeout=300) as response:
            response.raise_for_status()

            for chunk in response.iter_lines():
                if chunk:
                    decoded_chunk = chunk.decode('utf-8')
                    try:
                        json_chunk = json.loads(decoded_chunk)
                        response_part = json_chunk.get("response", "")

                        # æ— è®ºå¦‚ä½•ï¼Œéƒ½æµå¼æ‰“å°åˆ°æ§åˆ¶å°
                        print(response_part, end="", flush=True)

                        # å…ˆæ”¶é›†æ‰€æœ‰åŸå§‹æ•°æ®å—
                        raw_full_response.append(response_part)

                    except json.JSONDecodeError:
                        print(f"\n[Warning: Could not decode a JSON chunk: {decoded_chunk}]")

            print()  # æ¢è¡Œ

            # â­ æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨æ‰€æœ‰æ•°æ®æ¥æ”¶å®Œæ¯•åï¼Œå¯¹å®Œæ•´å“åº”è¿›è¡Œä¸€æ¬¡æ€§æ¸…ç†
            complete_text = "".join(raw_full_response).strip()

            # 1. ç§»é™¤æ‰€æœ‰ <think>...</think> æ ‡ç­¾åŠå…¶å†…å®¹
            clean_text = re.sub(r'<think>.*?</think>', '', complete_text, flags=re.DOTALL)

            # 2. ç§»é™¤å¯èƒ½å­˜åœ¨çš„å¤šä½™çš„ markdown ä»£ç å—æ ‡è¯†
            #    ä½¿ç”¨ strip() æ¥ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ ```markdown å’Œ ```
            clean_text = clean_text.strip()
            if clean_text.startswith("```markdown"):
                clean_text = clean_text[len("```markdown"):].strip()
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3].strip()

            return clean_text

    except requests.exceptions.RequestException as e:
        print(f"\nâŒ  Error calling Ollama API for {file_path}: {e}")
        return f"Error: Could not get analysis from Ollama API. Details: {e}"
    except Exception as e:
        print(f"\nâŒ  An unexpected error occurred during analysis of {file_path}: {e}")
        return f"Error: An unexpected error occurred. Details: {e}"


def is_excluded(path: Path, root: Path) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æˆ–ç›®å½•æ˜¯å¦åº”è¯¥è¢«æ’é™¤ã€‚"""
    if path.suffix.lower() in EXCLUDE_EXTENSIONS:
        return True
    relative_parts = path.relative_to(root).parts
    for part in relative_parts:
        if part in EXCLUDE_DIRS:
            return True
    return False


def main(project_path: str):
    """
    ä¸»å‡½æ•°ï¼Œéå†é¡¹ç›®ï¼Œè°ƒç”¨AIåˆ†æï¼Œå¹¶å¢é‡ç”ŸæˆæŠ¥å‘Šã€‚
    """
    root_path = Path(project_path)
    if not root_path.is_dir():
        print(f"âŒ Error: The provided path '{project_path}' is not a valid directory.")
        return

    script_dir = Path(__file__).parent
    output_path = script_dir / OUTPUT_FILENAME
    history_path = script_dir / HISTORY_FILENAME

    # åŠ è½½å†å²è®°å½•
    history_data = load_history(history_path)

    print(f"ğŸš€ Starting analysis of project: {root_path.resolve()}")
    print(f"ğŸ¤– Using Ollama model: {OLLAMA_MODEL}")
    print(f"ğŸ’¾ Using history file: {history_path.resolve()}")
    print(f"ğŸ“„ Report will be saved to: {output_path.resolve()}")

    all_files: List[Path] = [
        path for path in root_path.rglob("*")
        if path.is_file() and not is_excluded(path, root_path)
    ]
    total_files = len(all_files)

    # ä»…åœ¨æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨æ—¶å†™å…¥å¤´éƒ¨
    if not output_path.exists():
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"# ğŸ¤– AI Analysis Report for {root_path.name}\n\n")
            f.write("This report provides an AI-driven analysis of the key files in the repository.\n\n")

    files_to_analyze = []
    for file_path in all_files:
        relative_path_str = file_path.relative_to(root_path).as_posix()
        # æ£€æŸ¥å†å²è®°å½•
        if history_data.get(relative_path_str, {}).get("analysis_count", 0) >= 1:
            print(f"âœ…  Skipping (already analyzed): {relative_path_str}")
            continue
        files_to_analyze.append(file_path)

    print(f"ğŸ” Found {total_files} total files. Need to analyze {len(files_to_analyze)} new files.")

    for i, file_path in enumerate(files_to_analyze):
        print(f"\n--- Processing new file {i + 1}/{len(files_to_analyze)} ---")
        relative_path_str = file_path.relative_to(root_path).as_posix()

        try:
            content = file_path.read_text(encoding="utf-8")

            if len(content.strip()) == 0:
                print(f"âš ï¸  Skipping empty file: {relative_path_str}")
                analysis_result = "File is empty."
            elif len(content) > 100000:
                print(f"âš ï¸  Skipping large file: {relative_path_str}")
                analysis_result = "File is too large to be analyzed."
            else:
                analysis_result = analyze_file_with_ollama(relative_path_str, content)

            with open(output_path, "a", encoding="utf-8") as report_file:
                report_file.write(f"## `{relative_path_str}`\n\n")
                report_file.write(f"{analysis_result}\n\n")
                report_file.write("---\n\n")

            # â­ æ›´æ–°å¹¶ä¿å­˜å†å²è®°å½•
            history_data[relative_path_str] = {"analysis_count": 1}
            save_history(history_path, history_data)

        except Exception as e:
            print(f"âŒ  Could not read or process file {relative_path_str}: {e}")
            with open(output_path, "a", encoding="utf-8") as report_file:
                report_file.write(f"## `{relative_path_str}`\n\n")
                report_file.write(f"Could not process this file. Error: {e}\n\n---\n\n")

    print(f"\nğŸ‰ Analysis complete! Report is up to date at {output_path.resolve()}")


if __name__ == "__main__":
    if not PROJECT_TO_ANALYZE_PATH or not Path(PROJECT_TO_ANALYZE_PATH).is_dir():
        print(f"âŒ é”™è¯¯: è¯·åœ¨è„šæœ¬é¡¶éƒ¨çš„ 'PROJECT_TO_ANALYZE_PATH' å˜é‡ä¸­è®¾ç½®ä¸€ä¸ªæœ‰æ•ˆçš„é¡¹ç›®ç»å¯¹è·¯å¾„ã€‚")
        print(f"å½“å‰è®¾ç½®çš„å€¼æ˜¯: '{PROJECT_TO_ANALYZE_PATH}'")
        sys.exit(1)
    main(PROJECT_TO_ANALYZE_PATH)