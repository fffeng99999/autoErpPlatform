# # --PROJECT-COMMENT-BLOCK--
# File Path: repo_analyzer.py
# Author:
# Create Date:
# Description: A tool to analyze a software repository using a local Ollama model,
#              featuring streaming output, incremental reporting, and analysis history.
#              This version saves analysis in a mirrored directory structure.
# # --PROJECT-COMMENT-BLOCK--

import os
import sys
import json
import re
from pathlib import Path
import requests
from typing import List, Set, Dict

# --- é…ç½® ---

PROJECT_TO_ANALYZE_PATH = r"D:\b666\firecrawl"

# OLLAMA API çš„ç«¯ç‚¹
OLLAMA_API_URL = "http://localhost:11964/api/generate"
# ä½¿ç”¨çš„ Ollama æ¨¡å‹åç§°
OLLAMA_MODEL = "qwen3:latest"
# è¾“å‡ºåˆ†ææ–‡ä»¶çš„æ ¹ç›®å½•å
OUTPUT_ROOT_DIR = "analysis_output"
# å†å²è®°å½•æ–‡ä»¶å
HISTORY_FILENAME = ".repo_analysis_history.json"

# ç›®å½•å’Œæ–‡ä»¶æ’é™¤è§„åˆ™
EXCLUDE_DIRS: Set[str] = {
    ".git", ".venv", "venv", ".idea", ".vscode", "__pycache__",
    "node_modules", "build", "dist", "target", ".DS_Store", "logs",
}
EXCLUDE_EXTENSIONS: Set[str] = {
    ".pyc", ".log", ".tmp", ".swp", ".bak", ".zip", ".tar.gz", ".rar",
    ".png", ".jpg", ".jpeg", ".gif", ".svg", ".ico", ".mp4", ".mp3", ".wav",
}


def load_history(history_path: Path) -> Dict:
    """ä»JSONæ–‡ä»¶åŠ è½½åˆ†æå†å²ã€‚"""
    if not history_path.exists():
        return {}
    try:
        with open(history_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except (json.JSONDecodeError, IOError) as e:
        print(f"âš ï¸  Warning: Could not load or parse history file '{history_path}'. Starting fresh. Error: {e}")
        return {}


def save_history(history_path: Path, history_data: Dict):
    """å°†åˆ†æå†å²ä¿å­˜åˆ°JSONæ–‡ä»¶ã€‚"""
    try:
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(history_data, f, indent=4)
    except IOError as e:
        print(f"âŒ  Error saving history file '{history_path}': {e}")


def analyze_file_with_ollama(file_path: str, file_content: str) -> str:
    """
    ä½¿ç”¨ Ollama API åˆ†æå•ä¸ªæ–‡ä»¶çš„å†…å®¹ï¼Œå¹¶æµå¼è¾“å‡ºåˆ°æ§åˆ¶å°ã€‚
    """

    prompt = f"""
    ä½œä¸ºè½¯ä»¶æ¶æ„å¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹ä»£ç æ–‡ä»¶ã€‚

    æ–‡ä»¶è·¯å¾„ï¼š`{file_path}`

    æ–‡ä»¶å†…å®¹ï¼š
    {file_content}


    æ‚¨çš„åˆ†æåº”ç®€æ´æ˜äº†ï¼Œå¹¶é‡‡ç”¨Markdownæ ¼å¼ã€‚è¯·è¯†åˆ«ä»¥ä¸‹å†…å®¹ï¼š
    1. **ä¸»è¦ç›®çš„**ï¼šè¯¥æ–‡ä»¶çš„ä¸»è¦èŒè´£æ˜¯ä»€ä¹ˆï¼Ÿ
    2. **å…³é”®ç»„ä»¶**ï¼šç®€è¦æè¿°ä¸»è¦åŠŸèƒ½ã€ç±»æˆ–ç»„ä»¶åŠå…¶ä½œç”¨ã€‚
    3. **ä¾èµ–é¡¹**ï¼šè¯¥æ–‡ä»¶å¯èƒ½ä¸å…¶ä»–å“ªäº›é¡¹ç›®éƒ¨åˆ†äº§ç”Ÿäº¤äº’ï¼Ÿ
    4. **æ”¹è¿›å»ºè®®**ï¼šæä¾›ä¸€ä¸ªå…·ä½“çš„æ”¹è¿›å»ºè®®ï¼ˆä¾‹å¦‚ï¼šé‡æ„ã€å‘½åä¼˜åŒ–ã€æ·»åŠ æµ‹è¯•ç­‰ï¼‰ã€‚
    """

    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False
    }

    raw_full_response = []
    print(f"\nğŸ§   Analyzing: {file_path}...")

    try:
        with requests.post(OLLAMA_API_URL, json=payload, stream=True, timeout=300) as response:
            response.raise_for_status()

            for chunk in response.iter_lines():
                if chunk:
                    decoded_chunk = chunk.decode('utf-8')
                    try:
                        json_chunk = json.loads(decoded_chunk)
                        response_part = json_chunk.get("response", "")
                        print(response_part, end="", flush=True)
                        raw_full_response.append(response_part)
                    except json.JSONDecodeError:
                        print(f"\n[Warning: Could not decode a JSON chunk: {decoded_chunk}]")

            print()

            complete_text = "".join(raw_full_response).strip()
            clean_text = re.sub(r'<think>.*?</think>', '', complete_text, flags=re.DOTALL)
            clean_text = clean_text.strip()
            if clean_text.startswith("```markdown"):
                clean_text = clean_text[len("```markdown"):].strip()
            if clean_text.startswith("```typescript"):
                clean_text = clean_text[len("```typescript"):].strip()
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3].strip()

            return clean_text

    except requests.exceptions.RequestException as e:
        print(f"\nâŒ  Error calling Ollama API for {file_path}: {e}")
        return f"Error: Could not get analysis from Ollama API. Details: {e}"
    except Exception as e:
        print(f"\nâŒ  An unexpected error occurred during analysis of {file_path}: {e}")
        return f"Error: An unexpected error occurred. Details: {e}"


def is_excluded(path: Path, root: Path) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æˆ–ç›®å½•æ˜¯å¦åº”è¯¥è¢«æ’é™¤ã€‚"""
    if path.suffix.lower() in EXCLUDE_EXTENSIONS:
        return True
    relative_parts = path.relative_to(root).parts
    for part in relative_parts:
        if part in EXCLUDE_DIRS:
            return True
    return False


def main(project_path: str):
    """
    ä¸»å‡½æ•°ï¼Œéå†é¡¹ç›®ï¼Œè°ƒç”¨AIåˆ†æï¼Œå¹¶ä»¥é•œåƒç›®å½•ç»“æ„å¢é‡ç”ŸæˆæŠ¥å‘Šã€‚
    """
    root_path = Path(project_path)
    if not root_path.is_dir():
        print(f"âŒ Error: The provided path '{project_path}' is not a valid directory.")
        return

    script_dir = Path(__file__).parent
    # â­ æ ¸å¿ƒä¿®æ”¹ 1ï¼šå®šä¹‰å¹¶åˆ›å»ºè¾“å‡ºçš„æ ¹ç›®å½•
    output_dir = script_dir / OUTPUT_ROOT_DIR
    output_dir.mkdir(exist_ok=True)

    history_path = script_dir / HISTORY_FILENAME
    history_data = load_history(history_path)

    print(f"ğŸš€ Starting analysis of project: {root_path.resolve()}")
    print(f"ğŸ¤– Using Ollama model: {OLLAMA_MODEL}")
    print(f"ğŸ’¾ Using history file: {history_path.resolve()}")
    print(f"ğŸ“„ Analysis files will be saved in: {output_dir.resolve()}")

    all_files: List[Path] = [
        path for path in root_path.rglob("*")
        if path.is_file() and not is_excluded(path, root_path)
    ]

    files_to_analyze = []
    for file_path in all_files:
        relative_path_str = file_path.relative_to(root_path).as_posix()
        if history_data.get(relative_path_str, {}).get("analysis_count", 0) >= 1:
            print(f"âœ…  Skipping (already analyzed): {relative_path_str}")
            continue
        files_to_analyze.append(file_path)

    print(f"ğŸ” Found {len(all_files)} total files. Need to analyze {len(files_to_analyze)} new files.")

    for i, file_path in enumerate(files_to_analyze):
        print(f"\n--- Processing new file {i + 1}/{len(files_to_analyze)} ---")
        relative_path_str = file_path.relative_to(root_path).as_posix()

        try:
            # â­ æ ¸å¿ƒä¿®æ”¹ 2ï¼šæ„å»ºé•œåƒç›®å½•ç»“æ„å’Œæ–°çš„æ–‡ä»¶å
            relative_file_path = file_path.relative_to(root_path)
            new_filename = f"{file_path.name}-analysis.md"
            target_analysis_path = output_dir / relative_file_path.with_name(new_filename)

            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            target_analysis_path.parent.mkdir(parents=True, exist_ok=True)

            content = file_path.read_text(encoding="utf-8")

            if len(content.strip()) == 0:
                analysis_result = f"# Analysis for `{relative_path_str}`\n\nFile is empty."
            elif len(content) > 100000:
                analysis_result = f"# Analysis for `{relative_path_str}`\n\nFile is too large to be analyzed."
            else:
                ai_analysis = analyze_file_with_ollama(relative_path_str, content)
                analysis_result = f"# Analysis for `{relative_path_str}`\n\n{ai_analysis}"

            # æ ¸å¿ƒä¿®æ”¹ 3ï¼šå†™å…¥åˆ°ç‹¬ç«‹çš„åˆ†ææ–‡ä»¶ä¸­
            with open(target_analysis_path, "w", encoding="utf-8") as report_file:
                report_file.write(analysis_result)
            print(f"ğŸ“„ Report saved to: {target_analysis_path}")

            history_data[relative_path_str] = {"analysis_count": 1}
            save_history(history_path, history_data)

        except Exception as e:
            print(f"âŒ  Could not read or process file {relative_path_str}: {e}")

    print(f"\nğŸ‰ Analysis complete! All reports have been saved in {output_dir.resolve()}")


if __name__ == "__main__":
    if not PROJECT_TO_ANALYZE_PATH or not Path(PROJECT_TO_ANALYZE_PATH).is_dir():
        print(f"âŒ é”™è¯¯: è¯·åœ¨è„šæœ¬é¡¶éƒ¨çš„ 'PROJECT_TO_ANALYZE_PATH' å˜é‡ä¸­è®¾ç½®ä¸€ä¸ªæœ‰æ•ˆçš„é¡¹ç›®ç»å¯¹è·¯å¾„ã€‚")
        print(f"å½“å‰è®¾ç½®çš„å€¼æ˜¯: '{PROJECT_TO_ANALYZE_PATH}'")
        sys.exit(1)
    main(PROJECT_TO_ANALYZE_PATH)